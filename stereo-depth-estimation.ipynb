{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Stereo Depth Estimation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/gist/aa19059/aabe021138505b45e9f8d792ac7cea16/stereo-depth-estimation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRV1eOmZXt0G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "57d815bf-b2ef-4937-e03b-74b591dbadf7"
      },
      "source": [
        "pip install pypfm"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pypfm in /usr/local/lib/python3.6/dist-packages (1.4.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pypfm) (1.18.5)\n",
            "Requirement already satisfied: pyzfp in /usr/local/lib/python3.6/dist-packages (from pypfm) (0.3.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUo0NAIuXxKi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from types import *\n",
        "import torch \n",
        "from torchvision import transforms\n",
        "import torch.nn as nn\n",
        "import tensorflow as tf\n",
        "from torch import optim\n",
        "from torch.autograd import Variable\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "from pypfm import PFMLoader\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "import os\n",
        "import glob\n",
        "from PIL import Image\n",
        "from torch.utils.data import random_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gK1HPCdSYEDz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Depth(Dataset):\n",
        "\n",
        "\n",
        "  def __init__(self, pathh, transform=None):\n",
        "    self.loader = PFMLoader(color=False, compress=False)\n",
        "    self.transform = transform\n",
        "    self.pathh = pathh\n",
        "    self.img_size = (320,240)\n",
        "  \n",
        "    self.files_left = sorted(glob.glob(os.path.join(self.pathh,'left','*.png')))\n",
        "    self.files_right = sorted(glob.glob(os.path.join(self.pathh,'right','*.png')))\n",
        "    self.pfm_array = sorted(glob.glob(os.path.join(self.pathh,'disparity','*.pfm')))\n",
        "   \n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.pfm_array)\n",
        "  \n",
        "  \n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    \n",
        "    image_left = Image.open(self.files_left[idx])\n",
        "    image_left = image_left.resize(self.img_size)\n",
        "    image_left = np.array(image_left)\n",
        "\n",
        "\n",
        "    image_right = Image.open(self.files_right[idx])\n",
        "    image_right= image_right.resize(self.img_size)\n",
        "    image_right = np.array(image_right)\n",
        "\n",
        "    pfm = self.loader.load_pfm(self.pfm_array[idx])\n",
        "    pfm = np.array(pfm)\n",
        "    pfm = cv2.resize(pfm,self.img_size)\n",
        "    pfm = np.flip(pfm,axis=0).copy()\n",
        "    target_tr = transforms.ToTensor()\n",
        "    pfm = target_tr(pfm)\n",
        "\n",
        "    if self.transform is not None:\n",
        "        image_left = self.transform(image_left)\n",
        "        image_right = self.transform(image_right)\n",
        "    \n",
        "    \n",
        "    return image_left,  image_right, pfm\n",
        "   \n",
        "    \n",
        "    \n",
        "\n",
        "l = cv2.imread('/content/left/0006.png')\n",
        "\n",
        "cv2_imshow(l)\n",
        "\n",
        "p = cv2.imread('/content/right/0006.png')\n",
        "\n",
        "cv2_imshow(p)\n",
        "\n",
        "loader = PFMLoader(color=False, compress=False)\n",
        "\n",
        "pfm= loader.load_pfm('/content/disparity/0006.pfm')\n",
        "\n",
        "img = np.asarray(pfm).astype(np.uint8)\n",
        "img = cv2.flip(img,0)\n",
        "\n",
        "cv2_imshow(img)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smZh5NkwqDjy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7xK_HtpYEwd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transform = transforms.Compose([\n",
        "              transforms.ToTensor(),\n",
        "              transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
        "                                    std=[0.229, 0.224, 0.225])\n",
        "               ])\n",
        "\n",
        "train_set = Depth('/content/drive/My Drive/Data/', transform)\n",
        "\n",
        "x = len(train_set)\n",
        "\n",
        "y = (80/100) * x\n",
        "\n",
        "z = round(y)\n",
        "\n",
        "a = x - round(y)\n",
        "\n",
        "train_loader , train_validation = random_split(train_set,[z, a])\n",
        "\n",
        "train_loader = DataLoader(train_loader,batch_size=32,shuffle=True,num_workers=8)\n",
        "\n",
        "#print(len(train_loader))\n",
        "\n",
        "train_validation = DataLoader(train_validation, batch_size=32, shuffle=True, num_workers=8)\n",
        "\n",
        "#print(len(train_validation))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RI_zfDMtYF5e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = nn.Sequential(nn.Conv2d(6,16,3,2,1),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Conv2d(16,32,3,2,1),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Conv2d(32,64,3,2,1),\n",
        "                      nn.ReLU(),\n",
        "                      nn.ConvTranspose2d(64,64,2,2),\n",
        "                      nn.ReLU(),\n",
        "                      nn.ConvTranspose2d(64,32,2,2),\n",
        "                      nn.ReLU(),\n",
        "                      nn.ConvTranspose2d(32,1,2,2),\n",
        "                      nn.ReLU()\n",
        ")\n",
        "    \n",
        "\n",
        "#model.cuda()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5a_N_T8OYHF_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input = torch.randn((1,6,240,320),dtype = torch.float32)\n",
        "\n",
        "#model(input).size()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5c7EP8CeYH9d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.MSELoss() \n",
        "optimizer = optim.Adam(model.parameters(),lr=0.01, weight_decay=5e-4)\n",
        "num_epochs = 50\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJi3anwkYJGw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    total = 0\n",
        "    correct = 0\n",
        "\n",
        "    for batch_idx, batch in enumerate (train_loader):\n",
        "        img_l, img_r, target_pfm = batch\n",
        "        img = torch.cat((img_l, img_r),1)\n",
        "        outputs = model(img.cuda())\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        loss = criterion(outputs, target_pfm.cuda())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss+=loss.item()\n",
        "    print('Results after epoch %d'% (epoch + 1))\n",
        "\n",
        "    print('Training Loss: %.3f'%(train_loss/(batch_idx + 1)))\n",
        "    \n",
        "    model.eval()\n",
        "    valid_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for batch_idx, batch in enumerate (train_validation):\n",
        "        img_l, img_r, target_pfm = batch\n",
        "        img = torch.cat((img_l, img_r),1)\n",
        "        with torch.no_grad():\n",
        "            outputs = model(img.cuda())\n",
        "            loss = criterion(outputs, target_pfm.cuda())\n",
        "\n",
        "        valid_loss+= loss.item()\n",
        "    print('Validation Loss: %.3f ' % (valid_loss / (batch_idx + 1)))\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}